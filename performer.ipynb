{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faFPZgkzFaft"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/lucidrains/performer-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd performer-pytorch"
      ],
      "metadata": {
        "id": "c6cVaqB3Fiuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install performer-pytorch"
      ],
      "metadata": {
        "id": "h_1QFrWwFoAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "KK-jL7MnFrVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "BozzYDmZFuVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "DEVICE"
      ],
      "metadata": {
        "id": "dqlALkZ0SQiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "price_data = pd.read_csv('/content/btc-usdt-1.csv')"
      ],
      "metadata": {
        "id": "5ZJ_8stySRfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = (price_data.bid_price + price_data.ask_price) / 2\n",
        "\n",
        "train_data, val_data = train_test_split(input_data, test_size=0.33)\n",
        "train_data.shape, val_data.shape"
      ],
      "metadata": {
        "id": "r5JPHVukSRhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# scaler = MinMaxScaler(feature_range=(-1, 1)) \n",
        "# train_data = scaler.fit_transform(train_data.values.reshape(-1, 1)).reshape(-1)\n",
        "# val_data = scaler.transform(val_data.values.reshape(-1, 1)).reshape(-1) "
      ],
      "metadata": {
        "id": "fKDMmrnlaP5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "id": "mFZF9RHnNj-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data.astype(int)\n",
        "val_data = val_data.astype(int)"
      ],
      "metadata": {
        "id": "Z98IRX0DWkTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "id": "a302fR1wNnnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Nik212/crypto-transformers"
      ],
      "metadata": {
        "id": "5A8bUkCkSRjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import crypto_transformers.ts_dataset as ds\n",
        "import crypto_transformers.utils as utils\n",
        "\n",
        "def get_dataloader(data, enc_seq_len=60, dec_seq_len=120, step_size=1, batch_first=True, batch_size=None):\n",
        "    '''\n",
        "    E.g. if you want the model to consider the past 100\n",
        "    time steps in order to predict the future 50 \n",
        "    time steps, window_size = 100+50 = 150\n",
        "    \n",
        "    Args:\n",
        "    \n",
        "        enc_seq_len: int, length of input given to encoder\n",
        "\n",
        "        dec_seq_len: int, length of input given to decoder\n",
        "        \n",
        "        step_size: int, Step size, i.e. how many time steps does the moving window move at each step\n",
        "            \n",
        "    '''\n",
        "    \n",
        "    output_sequence_length = dec_seq_len # target sequence length. If hourly data and length = 48, you predict 2 days ahead\n",
        "\n",
        "    window_size = enc_seq_len + output_sequence_length # used to slice data into sub-sequences\n",
        "   \n",
        "    indices = utils.get_indices_entire_sequence(\n",
        "        data=data, \n",
        "        window_size=window_size, \n",
        "        step_size=step_size\n",
        "    )\n",
        "\n",
        "    # Making instance of custom dataset class\n",
        "    data = ds.TransformerDataset(\n",
        "        data=torch.tensor(data.tolist()).unsqueeze(1),\n",
        "        indices=indices,\n",
        "        enc_seq_len=enc_seq_len,\n",
        "        dec_seq_len=dec_seq_len,\n",
        "        target_seq_len=output_sequence_length\n",
        "    )\n",
        "\n",
        "    # Making dataloader\n",
        "    return DataLoader(data, batch_size, shuffle=False, num_workers=2) # replace 40 with your number"
      ],
      "metadata": {
        "id": "L2GnPQ_9SRla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE=64\n",
        "\n",
        "enc_seq_len=300\n",
        "dec_seq_len=60\n",
        "\n",
        "train_loader = get_dataloader(train_data, enc_seq_len, dec_seq_len, batch_size=BATCH_SIZE)\n",
        "val_loader = get_dataloader(val_data, enc_seq_len, dec_seq_len, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "1aMsYuLNSRnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = {'input_ids': next(iter(train_loader))[0]}\n",
        "val_loader = {'input_ids': next(iter(val_loader))[0]}"
      ],
      "metadata": {
        "id": "C0R3zx16SRpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_lightning"
      ],
      "metadata": {
        "id": "65P_PdtfSRsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "6n0gEqZ1TVi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "from performer_pytorch.autoregressive_wrapper import AutoregressiveWrapper\n",
        "from performer_pytorch import PerformerLM\n",
        "\n",
        "class LitGpt(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, weight_decay, lr, pretrained=False):\n",
        "        super().__init__()\n",
        "        self.weight_decay = weight_decay\n",
        "        self.lr = lr\n",
        "        self.model = PerformerLM(\n",
        "          num_tokens = 28512,\n",
        "          max_seq_len = 2048,             # max sequence length\n",
        "          dim = 512,                      # dimension\n",
        "          depth = 12,                     # layers\n",
        "          heads = 8,                      # heads\n",
        "          causal = True,                 # auto-regressive or not\n",
        "          nb_features = 1,              # number of random features, if not set, will default to (d * log(d)), where d is the dimension of each head\n",
        "          feature_redraw_interval = 1000, # how frequently to redraw the projection matrix, the more frequent, the slower the training\n",
        "          generalized_attention = False,  # defaults to softmax approximation, but can be set to True for generalized attention\n",
        "          kernel_fn = torch.nn.ReLU(),    # the kernel function to be used, if generalized attention is turned on, defaults to Relu\n",
        "          reversible = True,              # reversible layers, from Reformer paper\n",
        "          ff_chunks = 10,                 # chunk feedforward layer, from Reformer paper\n",
        "          use_scalenorm = False,          # use scale norm, from 'Transformers without Tears' paper\n",
        "          use_rezero = False,             # use rezero, from 'Rezero is all you need' paper\n",
        "          ff_glu = True,                  # use GLU variant for feedforward\n",
        "          emb_dropout = 0.1,              # embedding dropout\n",
        "          ff_dropout = 0.1,               # feedforward dropout\n",
        "          attn_dropout = 0.1,             # post-attn dropout\n",
        "          local_attn_heads = 4,           # 4 heads are local attention, 4 others are global performers\n",
        "          local_window_size = 256,        # window size of local attention\n",
        "          rotary_position_emb = True,     # use rotary positional embedding, which endows linear attention with relative positional encoding with no learned parameters. should always be turned on unless if you want to go back to old absolute positional encoding\n",
        "          shift_tokens = True             # shift tokens by 1 along sequence dimension before each block, for better convergence\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x, return_loss=True):\n",
        "        # in lightning, forward defines the prediction/inference actions\n",
        "        return self.model(x, return_loss=return_loss)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # training_step defined the train loop. It is independent of forward\n",
        "        loss = self(batch['input_ids'], return_loss=True)\n",
        "        loss = loss.mean()\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "        optimizer_grouped_parameters = [\n",
        "            {\n",
        "                \"params\": [p for n, p in self.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": self.weight_decay,\n",
        "            },\n",
        "            {\n",
        "                \"params\": [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": 0.0,\n",
        "            },\n",
        "        ]\n",
        "        optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=self.lr)\n",
        "        return [optimizer], []\n"
      ],
      "metadata": {
        "id": "iKdDyhTgg-En"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect(), torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "3h1cRva9TVlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_decay = 0.01\n",
        "lr = 2e-5\n",
        "autoencoder = LitGpt(weight_decay, lr)"
      ],
      "metadata": {
        "id": "At_lzqF7TgqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS=10\n",
        "\n",
        "\n",
        "model = autoencoder.to(DEVICE)"
      ],
      "metadata": {
        "id": "3G30NVLwTnm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "wb_logger = pl.loggers.WandbLogger(\n",
        "    name=f\"Informer|n_epochs={N_EPOCHS}|batch_size={BATCH_SIZE}|window_size={dec_seq_len}\",\n",
        "    project='sequential_data'\n",
        ")\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath='checkpoints',\n",
        "    monitor='val_MSE',\n",
        "    filename='{epoch:02d}-{val_f1:.3f}',\n",
        "    mode='min'\n",
        ")\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=N_EPOCHS,\n",
        "    logger=wb_logger,\n",
        "    accelerator='gpu',\n",
        "    devices=1,\n",
        "    benchmark=True,\n",
        "    callbacks=[checkpoint_callback]\n",
        ")"
      ],
      "metadata": {
        "id": "qhikWkPjToWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=N_EPOCHS,\n",
        "    gpus=1,\n",
        "    logger=wb_logger,\n",
        "    callbacks=[checkpoint_callback]    \n",
        "    )\n",
        "\n",
        "trainer.fit(model, train_loader, val_loader)\n",
        "\n",
        "wandb.finish()\n",
        "\n"
      ],
      "metadata": {
        "id": "6R_XqmL5Trkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    inp = random.choice(val_loader['input_ids'])\n",
        "    print(inp.shape)\n",
        "    pred = autoencoder(inp, DEVICE)\n",
        "    print(f'validation loss: {pred}')"
      ],
      "metadata": {
        "id": "wqwdI6lw3JlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.squeeze(pred).shape"
      ],
      "metadata": {
        "id": "uPkYI4_z_ok6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_data = torch.squeeze(torch.sum(pred, dim = 0)).numpy()"
      ],
      "metadata": {
        "id": "kkDXi-NLAGJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exp = -1* pred_data\n",
        "scaled_pred = exp/max(exp)\n",
        "print(scaled_pred)"
      ],
      "metadata": {
        "id": "C-MXHVYnWBon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1)) \n",
        "scaler.fit_transform(train_data.values.reshape(-1, 1)).reshape(-1)\n",
        "scaled_val_data = scaler.transform(val_data.values.reshape(-1, 1)).reshape(-1) "
      ],
      "metadata": {
        "id": "PCU60FBvCDov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_val_data"
      ],
      "metadata": {
        "id": "l5-Ooz4BVHrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_pred[:100]"
      ],
      "metadata": {
        "id": "viOT1mJHXeah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_val_data[:100]"
      ],
      "metadata": {
        "id": "T0ThchwKXgVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
        "\n",
        "plt.plot(range(100), scaled_pred[:100], color='r', label='predictions')\n",
        "plt.plot(range(100), scaled_val_data[:100], color='g', label='real')\n",
        "\n",
        "\n",
        "plt.xlabel(\"time\")\n",
        "plt.ylabel(\"Value\")\n",
        "plt.title(\"Autoregressive Predictions\")\n",
        "\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "I4YbNaTt_8Mi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W6BfB_6jBUFA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}